{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "L3qb7bShN28h"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enter consumer key and consumer secret\n",
        "consumer_key = input(\"Enter the consumer key:\")\n",
        "consumer_secret = input(\"Enter the consumer secret:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "d35pQY71QcJo"
      },
      "outputs": [],
      "source": [
        "def get_entities(text):\n",
        "    entities = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label'):\n",
        "                entities.append((chunk.label(), ' '.join(c[0] for c in chunk)))\n",
        "    return entities\n",
        "    \n",
        "def generate_wordcloud(text):\n",
        "    wordcloud = WordCloud(max_font_size=50).generate(text)\n",
        "    plt.figure()\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0WkmMD06N4kO"
      },
      "outputs": [],
      "source": [
        "auth = tweepy.OAuthHandler(\n",
        "   consumer_key, consumer_secret\n",
        ")\n",
        "\n",
        "api = tweepy.API(auth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "13Td7qCmOW5I"
      },
      "outputs": [],
      "source": [
        "# Search for a screen name (returns default of 20 results)\n",
        "screen_name=input(\"Enter the screen name for the user you're searching: \")\n",
        "try:\n",
        "    user = api.get_user(screen_name=screen_name)\n",
        "    timeline_results = user.timeline(tweet_mode=\"extended\", count=20)\n",
        "    results = []\n",
        "    for t in timeline_results:\n",
        "        date = t.created_at\n",
        "        user = t.user.name\n",
        "        if \"retweeted_status\" in dir(t):\n",
        "            text = t.retweeted_status.full_text\n",
        "        else:\n",
        "            text = t.full_text\n",
        "        results.append((user, date, text))\n",
        "    df = pd.DataFrame(results, columns=['User', 'Date', 'Full Text'])\n",
        "except Exception as e: \n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "lrGVRSBa9pnl"
      },
      "outputs": [],
      "source": [
        "# Get a list of entity types\n",
        "df['Entities'] = df['Full Text'].apply(lambda x: get_entities(x))\n",
        "all_entities = df['Entities'].to_list()\n",
        "entity_types = [i for j in all_entities for i in j]\n",
        "entity_types = list(set([e[0] for e in entity_types]))\n",
        "entity_types.insert(0, \"ALL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter the entities that are used to create the wordcloud\n",
        "filter_type = input(f\"Enter a filter type ({entity_types}): \")\n",
        "\n",
        "# Generate the wordcloud\n",
        "if filter_type == \"ALL\":\n",
        "    entities = [[entity[1] for entity in entities] for entities in all_entities]\n",
        "else:\n",
        "    entities = [[entity[1] for entity in entities if entity[0] == filter_type] for entities in all_entities]\n",
        "text = ' '.join([i for j in entities for i in j])\n",
        "generate_wordcloud(text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
